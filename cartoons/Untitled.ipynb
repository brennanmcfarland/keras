{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 67500)             270000    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 150, 450, 1)       0         \n",
      "_________________________________________________________________\n",
      "pixel_cnn_3 (PixelCNN)       (None, 150, 450, 1)       33        \n",
      "=================================================================\n",
      "Total params: 270,033\n",
      "Trainable params: 270,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\his eminence\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:153: UserWarning: Update your `PixelCNN` call to the Keras 2 API: `PixelCNN(1, (2, 16))`\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from keras.layers import Lambda\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "from skimage import io\n",
    "from skimage.transform import downscale_local_mean\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Multiply, Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Dense, Flatten, Activation, Reshape\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "# https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "data_root = 'E:/ML/keras/data/cartoons/'\n",
    "random.seed()\n",
    "\n",
    "# TODO: these two helper functions were copied directly from the example,\n",
    "# look at them closer when you get the chance\n",
    "def load_metadata():\n",
    "    metadata = []\n",
    "    with open(data_root + 'metadata.csv', 'r', newline='') as metadata_file:\n",
    "        reader = csv.reader(metadata_file, quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in reader:\n",
    "            metadatum = row[:2] + [int(n) for n in re.findall(r'\\d+', row[2])]\n",
    "            metadata.append(metadatum)\n",
    "    return metadata\n",
    "\n",
    "\n",
    "metadata = load_metadata()\n",
    "random.shuffle(metadata)\n",
    "metadata_train = metadata[len(metadata)//10:]\n",
    "metadata_test = metadata[:len(metadata_train)]\n",
    "num_data = len(metadata)\n",
    "\n",
    "classes = set([datum[0] for datum in metadata])\n",
    "# build a dictionary mapping between name strings and ids\n",
    "class_to_id = dict((n, i) for i, n in enumerate(classes))\n",
    "id_to_class = dict((i, n) for i, n in enumerate(classes))\n",
    "num_classes = len(classes)\n",
    "\n",
    "# if outside the tolerance range, return None (it's not a valid datum)\n",
    "# if to large, crop from both sides to fit\n",
    "# if to small, pad with maximum value (white) to fit\n",
    "def scale_to_target(image, initial_y, target_y, shrink_tolerance, grow_tolerance):\n",
    "    if(target_y-initial_y > grow_tolerance or initial_y-target_y > shrink_tolerance):\n",
    "        #print('image oustide acceptable dimensions, ', image.shape)\n",
    "        return None\n",
    "    elif(initial_y > target_y):\n",
    "        #print('shrinking to fit target dimensions')\n",
    "        return image[:target_y]\n",
    "    else: # initial_y <= target_y\n",
    "        #print('growing to fit target dimensions')\n",
    "        padding = (target_y-initial_y)//2\n",
    "        return np.pad(image, ((padding, target_y - initial_y - padding),(0,0)), 'maximum')\n",
    "\n",
    "\n",
    "# TODO: optimize the batches to use np arrays from the getgo?\n",
    "def get_batch(batch_size, metadata):\n",
    "    img_x, img_y = 150, 450\n",
    "    batch_x = np.zeros((batch_size, img_x, img_y), dtype=float)\n",
    "    batch_y = np.zeros((batch_size, num_classes), dtype=float)\n",
    "    for i in range(batch_size):\n",
    "        img_scaled = None\n",
    "        while img_scaled is None:\n",
    "            metadatum = metadata[random.randrange(len(metadata))]\n",
    "            # TODO: we'll need to make it color for some strips later\n",
    "            img_raw = io.imread(data_root + 'images/' + metadatum[0] + metadatum[1] + '.png', as_gray=True)\n",
    "            # print('raw image: ', img_raw.shape)\n",
    "            img_scaled = scale_to_target(img_raw, metadatum[2], img_x*2, 5, 120)\n",
    "        # put it in a tensor after downscaling it and padding it\n",
    "        img_downscaled = downscale_local_mean(img_scaled, (2, 2))\n",
    "        # normalize channel values\n",
    "        img_downscaled /= 255# TODO: test to see if this is actually helpful, maybe research it\n",
    "        batch_x[i] = np.pad(img_downscaled, ((0,0), (0, img_y-img_downscaled.shape[1])), 'maximum')\n",
    "        batch_y[i][class_to_id[metadatum[0]]] = 1\n",
    "    return np.expand_dims(batch_x, axis=3), batch_y\n",
    "    # TODO: need to have it differentiate different strip sizes, ie sunday vs weekday strips\n",
    "\n",
    "\n",
    "# TODO: may want to try using the ImageDataGenerator class, but the problem is that it would\n",
    "# have to be able to work with one batch at a time loaded with its respective metadata from\n",
    "# files\n",
    "# could write a quick script to rename all the images with ids and make that the first value in\n",
    "# each csv row, then use flow_from_directory and use that id to get the metadata, but I'm too\n",
    "# lazy to do that right now\n",
    "class DataProvider(Sequence):\n",
    "\n",
    "    metadata = None\n",
    "    batch_size = 1 # TODO: obviously we'll need to find the optimal batch size\n",
    "    \n",
    "    def __init__(self, metadata):\n",
    "        self.metadata = metadata\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = get_batch(self.batch_size, self.metadata)\n",
    "        return y, x\n",
    "\n",
    "\n",
    "# TODO: condense these repeated layer patterns into \"super layers\"?\n",
    "# TODO: obviously, this will need tweaking, try adding dropout, more layers, etc\n",
    "# if it gets an OOM error, the network or data input size or batch size has to be scaled down\n",
    "\n",
    "# TODO: does this need to correspond to the # output layers for hte encoder?\n",
    "latent_dim = 2 # TODO: this will probably need to be upped a lot (or does it, since it's not one-hot but just regular vectors?\n",
    "\n",
    "# TODO: probably will have to implement build and compute_output_shape since\n",
    "# it's not really supposed to inherit specifically from Conv2D\n",
    "class PixelCNN(Conv2D):\n",
    "    ''' Start w/ simple PixelCNN and then make it better once it works '''\n",
    "\n",
    "    def __init__(self, filters, rank, kernel_size, **kwargs):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        super(PixelCNN, self).__init__(filters, rank, kernel_size, **kwargs)\n",
    "\n",
    "    # this is where you will define your weights. This method must set\n",
    "    # self.built = True at the end, which can be done by calling\n",
    "    # super([Layer], self).build()\n",
    "    # implemented in base ok i think\n",
    "    #def build(self, input_shape):\n",
    "        \n",
    "    def _crop_right(self, x):\n",
    "        x_shape = K.int_shape(x)\n",
    "        return x[:,:,:x_shape[2]-1,:]\n",
    "\n",
    "    # this is where the layer's logic lives. Unless you want your layer to\n",
    "    # support masking, you only have to care about the first argument\n",
    "    # passed to call: the input tensor\n",
    "    def call(self, xW):\n",
    "        ''' calculate gated activation maps given input maps '''\n",
    "\n",
    "        # TODO: not sure why the example crops right, try it without it first\n",
    "        # print(xW.shape)\n",
    "        # xW = Lambda(self._crop_right)(xW)\n",
    "\n",
    "        # even res displays the right dimensions when manually throwing an error,\n",
    "        # so where  is it going wrong?\n",
    "        \n",
    "        # f and g are for the 2 sets of weights for the 2 terms in the activation\n",
    "        # function\n",
    "        # first apply the filters\n",
    "        xW_f = Lambda(lambda x: x[:,:,:,:self.filters])(xW)\n",
    "        xW_g = Lambda(lambda x: x[:,:,:,self.filters:])(xW)\n",
    "\n",
    "        # and then apply the activation functions\n",
    "        xW_f = Lambda(lambda x: K.tanh(x))(xW_f)\n",
    "        xW_g = Lambda(lambda x: K.sigmoid(x))(xW_g)\n",
    "\n",
    "        # and merge them\n",
    "        res = Multiply()([xW_f, xW_g])\n",
    "        \n",
    "        return res\n",
    "    # in case your layer modifies the shape of its input, you should\n",
    "    # specify here the shape transformation logic. This allows Keras to\n",
    "    # do automatic shape inference\n",
    "    # implemented in base ok i think\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "# decoder\n",
    "# upscales the image between convolutions until it gets to the original dim,\n",
    "# so using different sized images will require this to be adjusted\n",
    "input = Input(shape=(num_classes,), name='z_sampling')\n",
    "# layer = Dense(2700, activation='relu')(input)\n",
    "# layer = Dense(2700, activation='relu')(layer)\n",
    "# layer = Dense(2700, activation='relu')(layer)\n",
    "# layer = Reshape((30, 90, 1))(layer)\n",
    "# layer = Conv2DTranspose(32, (3, 3), padding='same', activation='sigmoid')(layer)\n",
    "# layer = Conv2DTranspose(32, (3, 3), padding='same', activation='sigmoid')(layer)\n",
    "# layer = UpSampling2D(size=(5, 5))(layer)\n",
    "# layer = Conv2DTranspose(32, (3, 3), padding='same', activation='sigmoid')(layer)\n",
    "#layer = UpSampling2D(size=(2, 2))(layer)\n",
    "# output = Conv2D(1, (3, 3), padding='same', activation='sigmoid')(layer)\n",
    "\n",
    "layer = Dense(67500, activation='sigmoid')(input)\n",
    "layer = Reshape((150, 450, 1))(layer)\n",
    "# TODO: the shape is the same as returned by Conv2D, but that also throws an error\n",
    "# substituting with Conv2D returns ValueError: cannot select an axis to squeeze out which has size not equal to one\n",
    "# args are filters, rank, kernel size\n",
    "output = PixelCNN(1, 2, 16)(layer)\n",
    "# layer = PixelCNN(32, 2, 16)(layer)\n",
    "# output = UpSampling2D(size=(6, 6))(layer)\n",
    "\n",
    "\n",
    "decoder = Model(input, output, name='decoder')\n",
    "\n",
    "original_dim = 150 * 450 # TODO: set this to just the dimensions of the input later instead of hard coding it\n",
    "optimizer = Adam(lr=.00001)\n",
    "decoder.compile(loss='binary_crossentropy', optimizer=optimizer) # TODO: find out which optimizer works best\n",
    "decoder.summary()\n",
    "\n",
    "\n",
    "progress_callback = LambdaCallback(on_epoch_end=report_epoch_progress)\n",
    "checkpoint_callback = ModelCheckpoint('./model-checkpoint.ckpt')\n",
    "tensorboard_callback = TensorBoard(log_dir='../logs/tensorboard-logs', write_images=True)\n",
    "callbacks = [progress_callback, checkpoint_callback, tensorboard_callback]\n",
    "\n",
    "img = None\n",
    "# TODO: add validation data (split the training data)\n",
    "data_train = DataProvider(metadata_train)\n",
    "data_test = DataProvider(metadata_test)\n",
    "epochs = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_epoch_progress(epoch, logs):\n",
    "    print('epoch progress report:')\n",
    "    for i in range(num_classes):\n",
    "        latent = np.zeros(num_classes)\n",
    "        latent[i] = 1\n",
    "        latent = np.expand_dims(latent, axis=0)\n",
    "        #latent = np.array([[0,0,0]])\n",
    "        print(latent.shape)\n",
    "        print(latent)\n",
    "        img = decoder.predict(latent, verbose=1)\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch progress report:\n",
      "(1, 3)\n",
      "[[1. 0. 0.]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[]\n",
      "(1, 3)\n",
      "[[0. 1. 0.]]\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[]\n",
      "(1, 3)\n",
      "[[0. 0. 1.]]\n",
      "1/1 [==============================] - 0s 0us/step\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "report_epoch_progress(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
